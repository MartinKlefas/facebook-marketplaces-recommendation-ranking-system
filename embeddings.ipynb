{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get everything set up as it was for the retrain step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchvision import  models\n",
    "\n",
    "\n",
    "data_dir = 'images/clean_image_data'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = torch.load('model_evaluation/feature/best_weights.pt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last layer is avgpool as it would be with resnet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer = model._modules.get('avgpool')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the test image into the right state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_processor\n",
    "pyImage = image_processor.fullPreProcess_Image(filePath='images/clean_image_data/0a1baaa8-4556-4e07-a486-599c05cce76c.jpg').unsqueeze(0)\n",
    "\n",
    "#Create a vector of zeros that will hold our feature vector\n",
    "\n",
    "my_embedding = torch.zeros(2048)\n",
    "\n",
    "#Define a function that will copy the output of a layer\n",
    "def copy_data(m, i, o):\n",
    "    my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
    "    \n",
    "# Attach that function to our selected layer\n",
    "\n",
    "h = layer.register_forward_hook(copy_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model on our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3251, 0.8771, 0.5917,  ..., 0.0200, 0.1635, 0.8196])\n"
     ]
    }
   ],
   "source": [
    "model(pyImage.to(device))\n",
    "\n",
    "# Detach our copy function from the layer\n",
    "h.remove()\n",
    "\n",
    "print(my_embedding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now works for a single image, so let's shunt it off into a function, then test that function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "second_embedding = image_processor.getEmbedding(image='images/clean_image_data/0a1baaa8-4556-4e07-a486-599c05cce76c.jpg',model=model)\n",
    "\n",
    "if torch.equal(my_embedding, second_embedding):\n",
    "    print(\"success\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That now works, let's get our list of images and classify them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing: 100%|██████████| 100% 12604/12604 [00:00]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>912bb259-3ad9-457b-9db1-ce1da9016057</td>\n",
       "      <td>6</td>\n",
       "      <td>[tensor(0.4134), tensor(0.3961), tensor(0.2943...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b166d305-b852-4bdd-83f4-465b20da94fa</td>\n",
       "      <td>6</td>\n",
       "      <td>[tensor(0.2127), tensor(0.1100), tensor(0.7573...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68f5a29d-0075-4d60-81c1-ab684a82e50c</td>\n",
       "      <td>6</td>\n",
       "      <td>[tensor(0.2206), tensor(0.4567), tensor(0.5249...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f6a309d7-d247-446a-9b5e-aceefdd4334d</td>\n",
       "      <td>6</td>\n",
       "      <td>[tensor(0.5860), tensor(1.0795), tensor(0.4006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2c2b3a6f-15b3-4289-937a-15482d9f5781</td>\n",
       "      <td>6</td>\n",
       "      <td>[tensor(0.2624), tensor(0.4993), tensor(0.0598...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  label  \\\n",
       "0  912bb259-3ad9-457b-9db1-ce1da9016057      6   \n",
       "1  b166d305-b852-4bdd-83f4-465b20da94fa      6   \n",
       "2  68f5a29d-0075-4d60-81c1-ab684a82e50c      6   \n",
       "3  f6a309d7-d247-446a-9b5e-aceefdd4334d      6   \n",
       "4  2c2b3a6f-15b3-4289-937a-15482d9f5781      6   \n",
       "\n",
       "                                           embedding  \n",
       "0  [tensor(0.4134), tensor(0.3961), tensor(0.2943...  \n",
       "1  [tensor(0.2127), tensor(0.1100), tensor(0.7573...  \n",
       "2  [tensor(0.2206), tensor(0.4567), tensor(0.5249...  \n",
       "3  [tensor(0.5860), tensor(1.0795), tensor(0.4006...  \n",
       "4  [tensor(0.2624), tensor(0.4993), tensor(0.0598...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "imageList =   pd.read_csv(filepath_or_buffer='training_data.csv')\n",
    "\n",
    "imageList['embedding'] =[image_processor.getEmbedding(image=os.path.join(data_dir,x +'.jpg'),model=model) for x in tqdm( imageList['id'],\n",
    "                                                bar_format='{l_bar}{bar}| {percentage:3.0f}% {n}/{total} [{remaining}{postfix}]',desc=\"Calculating Embeddings\")]\n",
    "\n",
    "imageList.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of those nasty tensor representations so we can serialise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>912bb259-3ad9-457b-9db1-ce1da9016057</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.41342562437057495, 0.396090567111969, 0.294...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b166d305-b852-4bdd-83f4-465b20da94fa</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.2126685529947281, 0.11002184450626373, 0.75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68f5a29d-0075-4d60-81c1-ab684a82e50c</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.22057314217090607, 0.4567006826400757, 0.52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f6a309d7-d247-446a-9b5e-aceefdd4334d</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.5859533548355103, 1.079506516456604, 0.4005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2c2b3a6f-15b3-4289-937a-15482d9f5781</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.2624373137950897, 0.49925994873046875, 0.05...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  label  \\\n",
       "0  912bb259-3ad9-457b-9db1-ce1da9016057      6   \n",
       "1  b166d305-b852-4bdd-83f4-465b20da94fa      6   \n",
       "2  68f5a29d-0075-4d60-81c1-ab684a82e50c      6   \n",
       "3  f6a309d7-d247-446a-9b5e-aceefdd4334d      6   \n",
       "4  2c2b3a6f-15b3-4289-937a-15482d9f5781      6   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.41342562437057495, 0.396090567111969, 0.294...  \n",
       "1  [0.2126685529947281, 0.11002184450626373, 0.75...  \n",
       "2  [0.22057314217090607, 0.4567006826400757, 0.52...  \n",
       "3  [0.5859533548355103, 1.079506516456604, 0.4005...  \n",
       "4  [0.2624373137950897, 0.49925994873046875, 0.05...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageList['embedding'] = [x.tolist() for x in imageList['embedding']]\n",
    "imageList.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throw it all into json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageList.to_json(\"embeddings.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring it back in and check that the serialisation worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           embedding  \\\n",
      "                                                self   \n",
      "0  [0.4134256244, 0.3960905671, 0.294250667100000...   \n",
      "1  [0.212668553, 0.11002184450000001, 0.757327497...   \n",
      "2  [0.22057314220000002, 0.4567006826, 0.52488499...   \n",
      "3  [0.5859533548, 1.0795065165, 0.4005952179, 0.1...   \n",
      "4  [0.2624373138, 0.4992599487, 0.0597878285, 0.1...   \n",
      "\n",
      "                                                      \n",
      "                                               other  \n",
      "0  [0.41342562437057495, 0.396090567111969, 0.294...  \n",
      "1  [0.2126685529947281, 0.11002184450626373, 0.75...  \n",
      "2  [0.22057314217090607, 0.4567006826400757, 0.52...  \n",
      "3  [0.5859533548355103, 1.079506516456604, 0.4005...  \n",
      "4  [0.2624373137950897, 0.49925994873046875, 0.05...  \n",
      "12604\n"
     ]
    }
   ],
   "source": [
    "newImageList = pd.read_json(\"embeddings.json\")\n",
    "\n",
    "print(newImageList.head().compare(imageList.head()))\n",
    "\n",
    "print(len(newImageList))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long story short, the serialised version has lower floating point precision than the unserialised one.\n",
    "\n",
    "Not the end of the world since we're finding \"broad\" similarity between images, but not ideal for some situations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Facebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
